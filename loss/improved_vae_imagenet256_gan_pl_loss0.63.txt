ImprovedVAE_Imagenet_Config()
	batch_size: 32
	beta1: 0.9
	beta2: 0.95
	channels: [64, 64, 128, 256, 256]
	crop_size: 256
	disc_start: 40000
	disc_weight: 0.5
	gpu_num: 3
	grad_clip: 1.0
	gradient_accumulation_steps: 2
	img_size: 256
	kl_weight: 5e-06
	layers: [3, 3, 3, 3]
	learning_rate: 0.0006
	lr_decay_iters: 400000
	max_iters: 400000
	min_lr: 1e-05
	num_epoch: 60
	pl_weight: 0.1
	warmup_iters: 1000
	z_channel: 16

total_params: 34.72M, encoder_params: 10.64M, decoder_params: 10.13M, discriminator_params: 2.77M, perceptual_params: 11.18M
[rank1]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank2]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W reducer.cpp:1360] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/home/work/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 256, 1, 1], strides() = [256, 1, 256, 256]
bucket_view.sizes() = [256, 256, 1, 1], strides() = [256, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/work/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 256, 1, 1], strides() = [256, 1, 256, 256]
bucket_view.sizes() = [256, 256, 1, 1], strides() = [256, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/work/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:266: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [256, 256, 1, 1], strides() = [256, 1, 256, 256]
bucket_view.sizes() = [256, 256, 1, 1], strides() = [256, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:322.)
  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
step 153500, loss 0.189, rec 0.079, kl 0.022, pl 0.020, g 0.068, w 0.052, d 1.123, lr: 0.0004117, consume 185.73s
step 154000, loss 0.136, rec 0.070, kl 0.023, pl 0.019, g 0.025, w 2.698, d 0.591, lr: 0.0004106, consume 352.86s
step 154500, loss 0.196, rec 0.069, kl 0.022, pl 0.019, g 0.085, w 0.083, d 0.161, lr: 0.0004095, consume 353.87s
step 155000, loss 0.273, rec 0.069, kl 0.022, pl 0.019, g 0.163, w 0.161, d 0.008, lr: 0.0004084, consume 353.59s
step 155500, loss 0.359, rec 0.068, kl 0.022, pl 0.019, g 0.249, w 0.249, d 0.007, lr: 0.0004074, consume 353.79s
step 156000, loss 0.440, rec 0.069, kl 0.022, pl 0.019, g 0.330, w 0.331, d 0.006, lr: 0.0004063, consume 354.33s
step 156500, loss 0.422, rec 0.068, kl 0.022, pl 0.019, g 0.313, w 0.314, d 0.004, lr: 0.0004052, consume 353.95s
step 157000, loss 0.451, rec 0.068, kl 0.022, pl 0.019, g 0.343, w 0.344, d 0.003, lr: 0.0004041, consume 353.61s
step 157500, loss 0.527, rec 0.068, kl 0.022, pl 0.019, g 0.418, w 0.420, d 0.004, lr: 0.0004030, consume 353.66s
step 158000, loss 0.528, rec 0.068, kl 0.022, pl 0.019, g 0.419, w 0.421, d 0.005, lr: 0.0004019, consume 354.59s
step 158500, loss 0.547, rec 0.068, kl 0.022, pl 0.019, g 0.438, w 0.439, d 0.003, lr: 0.0004008, consume 353.68s
step 159000, loss 0.513, rec 0.067, kl 0.022, pl 0.019, g 0.405, w 0.406, d 0.003, lr: 0.0003997, consume 353.68s
step 159500, loss 0.566, rec 0.067, kl 0.022, pl 0.019, g 0.458, w 0.460, d 0.003, lr: 0.0003986, consume 353.91s
step 160000, loss 0.492, rec 0.067, kl 0.022, pl 0.019, g 0.384, w 0.385, d 0.003, lr: 0.0003975, consume 354.67s
    valid loss: 7.347, rec 0.087, kl 6.270, pl 0.025, g 0.965, w 1.000, d 1.002, consume: 181.796s
epoch: 23, consume: 5072.454s
step 160500, loss 0.544, rec 0.067, kl 0.022, pl 0.019, g 0.436, w 0.437, d 0.006, lr: 0.0003964, consume 260.31s
step 161000, loss 0.545, rec 0.067, kl 0.022, pl 0.019, g 0.437, w 0.439, d 0.003, lr: 0.0003953, consume 355.60s
step 161500, loss 0.551, rec 0.067, kl 0.022, pl 0.019, g 0.443, w 0.445, d 0.003, lr: 0.0003942, consume 355.41s
step 162000, loss 0.568, rec 0.067, kl 0.022, pl 0.019, g 0.460, w 0.462, d 0.003, lr: 0.0003931, consume 355.11s
step 162500, loss 0.520, rec 0.066, kl 0.022, pl 0.019, g 0.413, w 0.415, d 0.003, lr: 0.0003920, consume 354.70s
step 163000, loss 0.536, rec 0.066, kl 0.022, pl 0.019, g 0.430, w 0.431, d 0.003, lr: 0.0003908, consume 354.26s
step 163500, loss 0.545, rec 0.067, kl 0.022, pl 0.019, g 0.438, w 0.440, d 0.003, lr: 0.0003897, consume 354.78s
step 164000, loss 0.566, rec 0.066, kl 0.022, pl 0.019, g 0.459, w 0.461, d 0.003, lr: 0.0003886, consume 353.83s
step 164500, loss 0.634, rec 0.067, kl 0.022, pl 0.019, g 0.526, w 0.528, d 0.003, lr: 0.0003875, consume 353.62s
step 165000, loss 0.579, rec 0.067, kl 0.022, pl 0.019, g 0.471, w 0.473, d 0.003, lr: 0.0003864, consume 353.55s
step 165500, loss 0.666, rec 0.067, kl 0.022, pl 0.019, g 0.559, w 0.561, d 0.003, lr: 0.0003853, consume 354.70s
step 166000, loss 0.597, rec 0.067, kl 0.022, pl 0.019, g 0.490, w 0.491, d 0.003, lr: 0.0003842, consume 353.80s
step 166500, loss 0.555, rec 0.066, kl 0.022, pl 0.019, g 0.448, w 0.449, d 0.002, lr: 0.0003830, consume 354.70s
    valid loss: 1.110, rec 0.086, kl 0.022, pl 0.025, g 0.977, w 1.000, d 1.008, consume: 147.783s
epoch: 24, consume: 4889.014s
step 167000, loss 0.614, rec 0.067, kl 0.022, pl 0.019, g 0.506, w 0.507, d 0.002, lr: 0.0003819, consume 138.48s
step 167500, loss 0.598, rec 0.066, kl 0.022, pl 0.019, g 0.491, w 0.491, d 0.002, lr: 0.0003808, consume 353.74s
step 168000, loss 0.607, rec 0.066, kl 0.022, pl 0.019, g 0.500, w 0.501, d 0.002, lr: 0.0003797, consume 355.48s
step 168500, loss 0.645, rec 0.067, kl 0.022, pl 0.019, g 0.537, w 0.537, d 0.002, lr: 0.0003785, consume 355.08s
step 169000, loss 0.634, rec 0.066, kl 0.022, pl 0.019, g 0.527, w 0.527, d 0.002, lr: 0.0003774, consume 354.00s
step 169500, loss 0.678, rec 0.066, kl 0.022, pl 0.019, g 0.571, w 0.572, d 0.002, lr: 0.0003763, consume 354.07s
step 170000, loss 0.702, rec 0.066, kl 0.022, pl 0.019, g 0.595, w 0.595, d 0.002, lr: 0.0003752, consume 354.26s
step 170500, loss 0.661, rec 0.066, kl 0.022, pl 0.019, g 0.555, w 0.555, d 0.002, lr: 0.0003740, consume 353.74s
step 171000, loss 0.675, rec 0.066, kl 0.022, pl 0.019, g 0.568, w 0.569, d 0.002, lr: 0.0003729, consume 354.29s
step 171500, loss 0.676, rec 0.066, kl 0.022, pl 0.019, g 0.569, w 0.570, d 0.002, lr: 0.0003718, consume 353.65s
step 172000, loss 0.663, rec 0.066, kl 0.022, pl 0.019, g 0.557, w 0.557, d 0.002, lr: 0.0003706, consume 353.65s
step 172500, loss 0.644, rec 0.066, kl 0.022, pl 0.019, g 0.537, w 0.538, d 0.002, lr: 0.0003695, consume 354.12s
step 173000, loss 0.619, rec 0.066, kl 0.022, pl 0.019, g 0.512, w 0.513, d 0.002, lr: 0.0003684, consume 354.28s
    valid loss: 48.617, rec 0.089, kl 47.517, pl 0.025, g 0.986, w 1.000, d 1.007, consume: 147.793s
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.25it/s]
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 16.37it/s]
FID:  308.63161490767686
epoch: 25, consume: 4935.791s
step 173500, loss 0.670, rec 0.066, kl 0.022, pl 0.018, g 0.563, w 0.563, d 0.002, lr: 0.0003672, consume 16.84s
step 174000, loss 0.687, rec 0.067, kl 0.022, pl 0.019, g 0.579, w 0.580, d 0.003, lr: 0.0003661, consume 352.85s
step 174500, loss 0.357, rec 0.068, kl 0.022, pl 0.019, g 0.248, w 0.439, d 0.471, lr: 0.0003650, consume 354.51s
step 175000, loss 0.211, rec 0.068, kl 0.022, pl 0.019, g 0.102, w 0.156, d 0.248, lr: 0.0003638, consume 353.63s
step 175500, loss 0.202, rec 0.068, kl 0.023, pl 0.019, g 0.093, w 0.373, d 0.326, lr: 0.0003627, consume 353.48s
step 176000, loss 0.439, rec 0.066, kl 0.022, pl 0.019, g 0.333, w 0.332, d 0.003, lr: 0.0003616, consume 353.55s
step 176500, loss 0.508, rec 0.066, kl 0.022, pl 0.019, g 0.401, w 0.401, d 0.002, lr: 0.0003604, consume 354.31s
step 177000, loss 0.536, rec 0.066, kl 0.022, pl 0.019, g 0.430, w 0.430, d 0.003, lr: 0.0003593, consume 354.05s
step 177500, loss 0.508, rec 0.066, kl 0.022, pl 0.019, g 0.401, w 0.402, d 0.005, lr: 0.0003581, consume 353.52s
step 178000, loss 0.559, rec 0.066, kl 0.022, pl 0.019, g 0.453, w 0.455, d 0.003, lr: 0.0003570, consume 353.56s
step 178500, loss 0.547, rec 0.065, kl 0.022, pl 0.019, g 0.441, w 0.443, d 0.003, lr: 0.0003558, consume 354.13s
step 179000, loss 0.547, rec 0.065, kl 0.022, pl 0.019, g 0.442, w 0.444, d 0.003, lr: 0.0003547, consume 353.70s
step 179500, loss 0.535, rec 0.066, kl 0.022, pl 0.018, g 0.428, w 0.430, d 0.003, lr: 0.0003536, consume 353.90s
step 180000, loss 0.536, rec 0.065, kl 0.022, pl 0.018, g 0.430, w 0.432, d 0.003, lr: 0.0003524, consume 354.06s
    valid loss: 1.103, rec 0.086, kl 0.025, pl 0.025, g 0.967, w 1.000, d 0.996, consume: 148.185s
epoch: 26, consume: 4880.725s
step 180500, loss 0.496, rec 0.065, kl 0.022, pl 0.018, g 0.391, w 0.392, d 0.003, lr: 0.0003513, consume 249.01s
step 181000, loss 0.477, rec 0.065, kl 0.022, pl 0.018, g 0.371, w 0.373, d 0.003, lr: 0.0003501, consume 354.17s
step 181500, loss 0.505, rec 0.065, kl 0.022, pl 0.018, g 0.400, w 0.402, d 0.004, lr: 0.0003490, consume 354.67s
step 182000, loss 0.519, rec 0.065, kl 0.022, pl 0.018, g 0.414, w 0.416, d 0.004, lr: 0.0003478, consume 354.79s
step 182500, loss 0.487, rec 0.065, kl 0.022, pl 0.018, g 0.382, w 0.384, d 0.003, lr: 0.0003467, consume 355.25s
step 183000, loss 0.638, rec 0.066, kl 0.022, pl 0.018, g 0.532, w 0.535, d 0.003, lr: 0.0003455, consume 354.45s
step 183500, loss 0.619, rec 0.066, kl 0.022, pl 0.018, g 0.513, w 0.515, d 0.004, lr: 0.0003444, consume 353.72s
step 184000, loss 0.575, rec 0.065, kl 0.022, pl 0.018, g 0.470, w 0.472, d 0.003, lr: 0.0003432, consume 354.73s
step 184500, loss 0.594, rec 0.065, kl 0.022, pl 0.018, g 0.488, w 0.491, d 0.003, lr: 0.0003421, consume 353.60s
step 185000, loss 0.573, rec 0.065, kl 0.022, pl 0.018, g 0.467, w 0.470, d 0.003, lr: 0.0003409, consume 353.71s
step 185500, loss 0.621, rec 0.065, kl 0.022, pl 0.018, g 0.515, w 0.518, d 0.003, lr: 0.0003398, consume 353.62s
step 186000, loss 0.596, rec 0.065, kl 0.022, pl 0.018, g 0.491, w 0.494, d 0.003, lr: 0.0003386, consume 355.32s
step 186500, loss 0.442, rec 0.064, kl 0.022, pl 0.018, g 0.337, w 0.339, d 0.003, lr: 0.0003375, consume 355.13s
    valid loss: 64.407, rec 0.087, kl 63.315, pl 0.024, g 0.981, w 1.000, d 1.006, consume: 148.358s
epoch: 27, consume: 4888.802s
step 187000, loss 0.624, rec 0.065, kl 0.022, pl 0.018, g 0.519, w 0.522, d 0.003, lr: 0.0003363, consume 127.32s
step 187500, loss 0.545, rec 0.065, kl 0.022, pl 0.018, g 0.439, w 0.441, d 0.003, lr: 0.0003351, consume 355.10s
step 188000, loss 0.493, rec 0.064, kl 0.022, pl 0.018, g 0.389, w 0.391, d 0.003, lr: 0.0003340, consume 355.34s
step 188500, loss 0.495, rec 0.065, kl 0.022, pl 0.018, g 0.390, w 0.392, d 0.003, lr: 0.0003328, consume 355.12s
step 189000, loss 0.533, rec 0.065, kl 0.022, pl 0.018, g 0.428, w 0.430, d 0.003, lr: 0.0003317, consume 354.77s
step 189500, loss 0.570, rec 0.064, kl 0.022, pl 0.018, g 0.465, w 0.468, d 0.003, lr: 0.0003305, consume 355.54s
step 190000, loss 0.636, rec 0.065, kl 0.022, pl 0.018, g 0.530, w 0.533, d 0.003, lr: 0.0003294, consume 354.84s
step 190500, loss 0.675, rec 0.065, kl 0.022, pl 0.018, g 0.570, w 0.572, d 0.003, lr: 0.0003282, consume 355.41s
step 191000, loss 0.587, rec 0.065, kl 0.022, pl 0.018, g 0.482, w 0.484, d 0.003, lr: 0.0003270, consume 354.05s
step 191500, loss 0.608, rec 0.065, kl 0.022, pl 0.018, g 0.502, w 0.505, d 0.003, lr: 0.0003259, consume 354.21s
step 192000, loss 0.486, rec 0.065, kl 0.022, pl 0.018, g 0.381, w 0.383, d 0.004, lr: 0.0003247, consume 353.64s
step 192500, loss 0.501, rec 0.064, kl 0.022, pl 0.018, g 0.396, w 0.399, d 0.003, lr: 0.0003236, consume 353.54s
step 193000, loss 0.605, rec 0.065, kl 0.022, pl 0.018, g 0.500, w 0.502, d 0.003, lr: 0.0003224, consume 353.74s
step 193500, loss 0.603, rec 0.064, kl 0.022, pl 0.018, g 0.498, w 0.501, d 0.003, lr: 0.0003213, consume 354.62s
    valid loss: 293.607, rec 0.091, kl 292.509, pl 0.024, g 0.983, w 1.000, d 1.004, consume: 147.756s
epoch: 28, consume: 4890.653s
step 194000, loss 0.581, rec 0.064, kl 0.022, pl 0.018, g 0.477, w 0.479, d 0.003, lr: 0.0003201, consume 358.92s
step 194500, loss 0.548, rec 0.064, kl 0.022, pl 0.018, g 0.443, w 0.445, d 0.003, lr: 0.0003189, consume 353.77s
step 195000, loss 0.454, rec 0.064, kl 0.022, pl 0.018, g 0.350, w 0.351, d 0.003, lr: 0.0003178, consume 354.27s
step 195500, loss 0.531, rec 0.064, kl 0.022, pl 0.018, g 0.426, w 0.427, d 0.002, lr: 0.0003166, consume 354.71s
step 196000, loss 0.526, rec 0.064, kl 0.022, pl 0.018, g 0.421, w 0.422, d 0.002, lr: 0.0003155, consume 355.02s
step 196500, loss 0.444, rec 0.064, kl 0.022, pl 0.018, g 0.340, w 0.341, d 0.002, lr: 0.0003143, consume 353.74s
step 197000, loss 0.388, rec 0.063, kl 0.022, pl 0.018, g 0.284, w 0.284, d 0.002, lr: 0.0003131, consume 354.39s
step 197500, loss 0.395, rec 0.064, kl 0.022, pl 0.018, g 0.290, w 0.291, d 0.002, lr: 0.0003120, consume 353.90s
step 198000, loss 0.426, rec 0.064, kl 0.022, pl 0.018, g 0.321, w 0.322, d 0.002, lr: 0.0003108, consume 354.20s
step 198500, loss 0.447, rec 0.064, kl 0.022, pl 0.018, g 0.343, w 0.344, d 0.002, lr: 0.0003096, consume 353.80s
step 199000, loss 0.589, rec 0.064, kl 0.022, pl 0.018, g 0.485, w 0.486, d 0.002, lr: 0.0003085, consume 354.48s
step 199500, loss 0.492, rec 0.064, kl 0.022, pl 0.018, g 0.387, w 0.388, d 0.002, lr: 0.0003073, consume 353.76s
step 200000, loss 0.297, rec 0.066, kl 0.023, pl 0.018, g 0.190, w 0.191, d 0.329, lr: 0.0003062, consume 354.29s
    valid loss: 417.755, rec 0.093, kl 417.069, pl 0.023, g 0.570, w 1.000, d 1.030, consume: 147.879s
epoch: 29, consume: 4884.535s
step 200500, loss 0.250, rec 0.066, kl 0.023, pl 0.018, g 0.143, w 0.142, d 0.277, lr: 0.0003050, consume 238.23s
step 201000, loss 0.350, rec 0.064, kl 0.022, pl 0.018, g 0.245, w 0.245, d 0.002, lr: 0.0003038, consume 353.97s
step 201500, loss 0.394, rec 0.064, kl 0.023, pl 0.018, g 0.289, w 0.289, d 0.003, lr: 0.0003027, consume 354.27s
step 202000, loss 0.422, rec 0.064, kl 0.022, pl 0.018, g 0.317, w 0.318, d 0.002, lr: 0.0003015, consume 355.41s
step 202500, loss 0.376, rec 0.064, kl 0.022, pl 0.018, g 0.272, w 0.272, d 0.002, lr: 0.0003004, consume 355.54s
step 203000, loss 0.444, rec 0.064, kl 0.022, pl 0.018, g 0.339, w 0.340, d 0.003, lr: 0.0002992, consume 353.79s
step 203500, loss 0.432, rec 0.064, kl 0.022, pl 0.018, g 0.327, w 0.328, d 0.002, lr: 0.0002980, consume 353.85s
step 204000, loss 0.477, rec 0.064, kl 0.022, pl 0.018, g 0.372, w 0.373, d 0.002, lr: 0.0002969, consume 353.80s
step 204500, loss 0.500, rec 0.064, kl 0.022, pl 0.018, g 0.395, w 0.396, d 0.002, lr: 0.0002957, consume 354.91s
step 205000, loss 0.279, rec 0.066, kl 0.023, pl 0.018, g 0.172, w 0.434, d 0.338, lr: 0.0002946, consume 353.96s
step 205500, loss 0.337, rec 0.064, kl 0.023, pl 0.018, g 0.232, w 0.232, d 0.003, lr: 0.0002934, consume 353.76s
step 206000, loss 0.353, rec 0.063, kl 0.022, pl 0.018, g 0.249, w 0.249, d 0.002, lr: 0.0002922, consume 354.30s
step 206500, loss 0.345, rec 0.064, kl 0.023, pl 0.018, g 0.240, w 0.240, d 0.002, lr: 0.0002911, consume 354.17s
    valid loss: 20.252, rec 0.088, kl 19.157, pl 0.023, g 0.985, w 1.000, d 1.007, consume: 148.017s
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.93it/s]
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 16.24it/s]
FID:  300.24392064907966
epoch: 30, consume: 4936.401s
step 207000, loss 0.456, rec 0.065, kl 0.022, pl 0.018, g 0.351, w 0.352, d 0.002, lr: 0.0002899, consume 115.50s
step 207500, loss 0.442, rec 0.064, kl 0.022, pl 0.018, g 0.338, w 0.338, d 0.004, lr: 0.0002888, consume 353.58s
step 208000, loss 0.391, rec 0.064, kl 0.022, pl 0.018, g 0.287, w 0.287, d 0.002, lr: 0.0002876, consume 354.88s
step 208500, loss 0.339, rec 0.064, kl 0.023, pl 0.018, g 0.235, w 0.235, d 0.001, lr: 0.0002864, consume 353.92s
step 209000, loss 0.380, rec 0.064, kl 0.023, pl 0.018, g 0.276, w 0.277, d 0.002, lr: 0.0002853, consume 354.44s
step 209500, loss 0.489, rec 0.064, kl 0.023, pl 0.018, g 0.384, w 0.384, d 0.002, lr: 0.0002841, consume 353.92s
step 210000, loss 0.491, rec 0.064, kl 0.022, pl 0.018, g 0.386, w 0.387, d 0.002, lr: 0.0002830, consume 354.68s
step 210500, loss 0.467, rec 0.064, kl 0.022, pl 0.018, g 0.363, w 0.363, d 0.002, lr: 0.0002818, consume 353.87s
step 211000, loss 0.580, rec 0.064, kl 0.022, pl 0.018, g 0.475, w 0.476, d 0.002, lr: 0.0002806, consume 354.02s
step 211500, loss 0.616, rec 0.064, kl 0.022, pl 0.018, g 0.511, w 0.512, d 0.002, lr: 0.0002795, consume 354.40s
step 212000, loss 0.570, rec 0.064, kl 0.022, pl 0.018, g 0.465, w 0.465, d 0.002, lr: 0.0002783, consume 354.74s
step 212500, loss 0.320, rec 0.064, kl 0.022, pl 0.018, g 0.216, w 0.216, d 0.001, lr: 0.0002772, consume 353.98s
step 213000, loss 0.263, rec 0.063, kl 0.022, pl 0.018, g 0.159, w 0.159, d 0.001, lr: 0.0002760, consume 354.68s
step 213500, loss 0.175, rec 0.066, kl 0.023, pl 0.018, g 0.068, w 0.072, d 0.341, lr: 0.0002749, consume 356.02s
    valid loss: 0.886, rec 0.093, kl 0.103, pl 0.021, g 0.668, w 1.000, d 0.983, consume: 147.311s
epoch: 31, consume: 4887.282s
step 214000, loss 0.127, rec 0.067, kl 0.023, pl 0.018, g 0.019, w 0.026, d 0.574, lr: 0.0002737, consume 348.48s
step 214500, loss 0.317, rec 0.064, kl 0.023, pl 0.018, g 0.212, w 0.212, d 0.034, lr: 0.0002725, consume 355.17s
step 215000, loss 0.421, rec 0.064, kl 0.023, pl 0.018, g 0.316, w 0.316, d 0.002, lr: 0.0002714, consume 355.13s
step 215500, loss 0.332, rec 0.064, kl 0.023, pl 0.018, g 0.228, w 0.228, d 0.002, lr: 0.0002702, consume 355.82s
step 216000, loss 0.320, rec 0.064, kl 0.023, pl 0.018, g 0.215, w 0.214, d 0.005, lr: 0.0002691, consume 355.55s
step 216500, loss 0.481, rec 0.064, kl 0.023, pl 0.018, g 0.376, w 0.377, d 0.002, lr: 0.0002679, consume 355.14s
step 217000, loss 0.410, rec 0.064, kl 0.023, pl 0.018, g 0.305, w 0.306, d 0.002, lr: 0.0002668, consume 355.04s
step 217500, loss 0.361, rec 0.064, kl 0.022, pl 0.018, g 0.257, w 0.257, d 0.001, lr: 0.0002656, consume 354.68s
step 218000, loss 0.345, rec 0.064, kl 0.022, pl 0.018, g 0.241, w 0.241, d 0.002, lr: 0.0002645, consume 353.87s
step 218500, loss 0.413, rec 0.064, kl 0.022, pl 0.018, g 0.309, w 0.309, d 0.002, lr: 0.0002633, consume 354.37s
step 219000, loss 0.291, rec 0.063, kl 0.023, pl 0.018, g 0.188, w 0.188, d 0.001, lr: 0.0002622, consume 354.18s
step 219500, loss 0.379, rec 0.064, kl 0.023, pl 0.018, g 0.274, w 0.274, d 0.004, lr: 0.0002610, consume 354.45s
step 220000, loss 0.417, rec 0.064, kl 0.023, pl 0.018, g 0.312, w 0.313, d 0.002, lr: 0.0002599, consume 353.97s
    valid loss: 324.557, rec 0.090, kl 323.463, pl 0.023, g 0.981, w 1.000, d 0.994, consume: 148.729s
epoch: 32, consume: 4893.944s
step 220500, loss 0.131, rec 0.067, kl 0.023, pl 0.018, g 0.023, w 1.871, d 0.551, lr: 0.0002587, consume 227.79s
step 221000, loss 0.330, rec 0.063, kl 0.023, pl 0.018, g 0.226, w 0.225, d 0.029, lr: 0.0002576, consume 355.00s
step 221500, loss 0.432, rec 0.064, kl 0.023, pl 0.018, g 0.328, w 0.329, d 0.002, lr: 0.0002564, consume 353.99s
step 222000, loss 0.447, rec 0.064, kl 0.022, pl 0.018, g 0.343, w 0.344, d 0.002, lr: 0.0002553, consume 353.90s
step 222500, loss 0.472, rec 0.064, kl 0.022, pl 0.018, g 0.368, w 0.369, d 0.002, lr: 0.0002542, consume 353.93s
step 223000, loss 0.430, rec 0.064, kl 0.022, pl 0.018, g 0.326, w 0.326, d 0.003, lr: 0.0002530, consume 355.11s
step 223500, loss 0.477, rec 0.064, kl 0.022, pl 0.018, g 0.372, w 0.373, d 0.002, lr: 0.0002519, consume 353.88s
step 224000, loss 0.441, rec 0.064, kl 0.022, pl 0.018, g 0.337, w 0.337, d 0.002, lr: 0.0002507, consume 354.02s
step 224500, loss 0.460, rec 0.064, kl 0.023, pl 0.018, g 0.355, w 0.356, d 0.002, lr: 0.0002496, consume 354.29s
step 225000, loss 0.447, rec 0.063, kl 0.023, pl 0.018, g 0.343, w 0.344, d 0.002, lr: 0.0002484, consume 354.73s
step 225500, loss 0.356, rec 0.063, kl 0.023, pl 0.018, g 0.252, w 0.252, d 0.002, lr: 0.0002473, consume 353.84s
step 226000, loss 0.553, rec 0.064, kl 0.022, pl 0.018, g 0.449, w 0.449, d 0.002, lr: 0.0002462, consume 353.95s
step 226500, loss 0.471, rec 0.064, kl 0.022, pl 0.018, g 0.366, w 0.366, d 0.002, lr: 0.0002450, consume 354.64s
    valid loss: 1.212, rec 0.085, kl 0.118, pl 0.022, g 0.986, w 1.000, d 1.005, consume: 147.966s
epoch: 33, consume: 4887.619s
step 227000, loss 0.318, rec 0.064, kl 0.023, pl 0.018, g 0.213, w 0.213, d 0.001, lr: 0.0002439, consume 104.92s
step 227500, loss 0.311, rec 0.063, kl 0.023, pl 0.018, g 0.208, w 0.208, d 0.002, lr: 0.0002428, consume 353.63s
step 228000, loss 0.432, rec 0.063, kl 0.023, pl 0.018, g 0.329, w 0.329, d 0.004, lr: 0.0002416, consume 353.84s
step 228500, loss 0.508, rec 0.064, kl 0.023, pl 0.018, g 0.404, w 0.405, d 0.002, lr: 0.0002405, consume 354.54s
step 229000, loss 0.476, rec 0.063, kl 0.023, pl 0.018, g 0.372, w 0.372, d 0.002, lr: 0.0002394, consume 354.33s
step 229500, loss 0.565, rec 0.064, kl 0.023, pl 0.018, g 0.461, w 0.462, d 0.002, lr: 0.0002382, consume 355.40s
step 230000, loss 0.576, rec 0.064, kl 0.023, pl 0.018, g 0.472, w 0.473, d 0.002, lr: 0.0002371, consume 355.25s
step 230500, loss 0.606, rec 0.064, kl 0.022, pl 0.018, g 0.501, w 0.502, d 0.002, lr: 0.0002360, consume 355.06s
step 231000, loss 0.497, rec 0.064, kl 0.022, pl 0.018, g 0.393, w 0.394, d 0.002, lr: 0.0002348, consume 354.91s
step 231500, loss 0.349, rec 0.063, kl 0.022, pl 0.018, g 0.245, w 0.246, d 0.002, lr: 0.0002337, consume 354.78s
step 232000, loss 0.384, rec 0.064, kl 0.023, pl 0.018, g 0.280, w 0.280, d 0.002, lr: 0.0002326, consume 355.90s
step 232500, loss 0.411, rec 0.063, kl 0.023, pl 0.018, g 0.307, w 0.308, d 0.002, lr: 0.0002315, consume 354.86s
step 233000, loss 0.422, rec 0.063, kl 0.023, pl 0.018, g 0.319, w 0.319, d 0.002, lr: 0.0002303, consume 354.85s
step 233500, loss 0.508, rec 0.064, kl 0.023, pl 0.018, g 0.403, w 0.404, d 0.002, lr: 0.0002292, consume 354.80s
    valid loss: 103.546, rec 0.086, kl 102.450, pl 0.023, g 0.986, w 1.000, d 1.001, consume: 148.796s
epoch: 34, consume: 4894.339s
step 234000, loss 0.478, rec 0.063, kl 0.023, pl 0.018, g 0.375, w 0.376, d 0.002, lr: 0.0002281, consume 338.72s
step 234500, loss 0.517, rec 0.064, kl 0.023, pl 0.018, g 0.413, w 0.414, d 0.002, lr: 0.0002270, consume 354.88s
step 235000, loss 0.777, rec 0.064, kl 0.023, pl 0.018, g 0.672, w 0.674, d 0.002, lr: 0.0002258, consume 354.69s
step 235500, loss 0.732, rec 0.064, kl 0.023, pl 0.018, g 0.627, w 0.629, d 0.002, lr: 0.0002247, consume 354.79s
step 236000, loss 0.637, rec 0.064, kl 0.023, pl 0.018, g 0.532, w 0.534, d 0.002, lr: 0.0002236, consume 355.28s
step 236500, loss 0.530, rec 0.064, kl 0.023, pl 0.018, g 0.425, w 0.427, d 0.002, lr: 0.0002225, consume 355.06s
step 237000, loss 0.421, rec 0.064, kl 0.023, pl 0.018, g 0.317, w 0.317, d 0.007, lr: 0.0002214, consume 354.66s
step 237500, loss 0.706, rec 0.064, kl 0.023, pl 0.018, g 0.601, w 0.603, d 0.002, lr: 0.0002203, consume 354.96s
step 238000, loss 0.705, rec 0.064, kl 0.023, pl 0.018, g 0.601, w 0.602, d 0.002, lr: 0.0002192, consume 354.89s
step 238500, loss 0.674, rec 0.063, kl 0.023, pl 0.018, g 0.570, w 0.572, d 0.002, lr: 0.0002180, consume 354.60s
step 239000, loss 0.719, rec 0.064, kl 0.023, pl 0.018, g 0.615, w 0.616, d 0.002, lr: 0.0002169, consume 355.05s
step 239500, loss 0.550, rec 0.063, kl 0.023, pl 0.018, g 0.446, w 0.447, d 0.002, lr: 0.0002158, consume 355.32s
step 240000, loss 0.438, rec 0.063, kl 0.023, pl 0.018, g 0.335, w 0.335, d 0.002, lr: 0.0002147, consume 354.65s
    valid loss: 1.127, rec 0.090, kl 0.023, pl 0.024, g 0.991, w 1.000, d 1.004, consume: 148.594s
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.61it/s]
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.79it/s]
FID:  307.9802329024601
epoch: 35, consume: 4945.940s
step 240500, loss 0.590, rec 0.064, kl 0.023, pl 0.018, g 0.485, w 0.486, d 0.002, lr: 0.0002136, consume 215.20s
step 241000, loss 0.740, rec 0.064, kl 0.023, pl 0.018, g 0.636, w 0.637, d 0.002, lr: 0.0002125, consume 357.18s
step 241500, loss 0.780, rec 0.064, kl 0.023, pl 0.018, g 0.676, w 0.677, d 0.002, lr: 0.0002114, consume 354.76s
step 242000, loss 0.899, rec 0.064, kl 0.023, pl 0.018, g 0.794, w 0.796, d 0.002, lr: 0.0002103, consume 353.71s
step 242500, loss 0.710, rec 0.064, kl 0.023, pl 0.018, g 0.605, w 0.606, d 0.002, lr: 0.0002092, consume 353.85s
step 243000, loss 0.664, rec 0.064, kl 0.022, pl 0.018, g 0.560, w 0.561, d 0.002, lr: 0.0002081, consume 354.07s
step 243500, loss 0.362, rec 0.063, kl 0.022, pl 0.018, g 0.258, w 0.258, d 0.001, lr: 0.0002070, consume 354.62s
step 244000, loss 0.234, rec 0.063, kl 0.023, pl 0.018, g 0.131, w 0.130, d 0.003, lr: 0.0002059, consume 353.78s
step 244500, loss 0.381, rec 0.063, kl 0.023, pl 0.018, g 0.277, w 0.278, d 0.003, lr: 0.0002048, consume 353.77s
step 245000, loss 0.395, rec 0.063, kl 0.023, pl 0.018, g 0.291, w 0.297, d 0.004, lr: 0.0002037, consume 354.15s
step 245500, loss 0.559, rec 0.063, kl 0.023, pl 0.018, g 0.455, w 0.458, d 0.003, lr: 0.0002027, consume 354.01s
step 246000, loss 0.555, rec 0.064, kl 0.023, pl 0.018, g 0.451, w 0.454, d 0.003, lr: 0.0002016, consume 354.21s
step 246500, loss 0.493, rec 0.063, kl 0.023, pl 0.018, g 0.390, w 0.392, d 0.003, lr: 0.0002005, consume 353.66s
    valid loss: 4.112, rec 0.085, kl 3.020, pl 0.023, g 0.984, w 1.000, d 1.003, consume: 147.912s
epoch: 36, consume: 4886.884s
step 247000, loss 0.737, rec 0.064, kl 0.023, pl 0.018, g 0.632, w 0.636, d 0.011, lr: 0.0001994, consume 93.24s
step 247500, loss 0.692, rec 0.064, kl 0.023, pl 0.018, g 0.588, w 0.591, d 0.003, lr: 0.0001983, consume 353.49s
step 248000, loss 1.034, rec 0.064, kl 0.023, pl 0.018, g 0.929, w 0.935, d 0.003, lr: 0.0001972, consume 354.13s
step 248500, loss 0.947, rec 0.064, kl 0.023, pl 0.018, g 0.843, w 0.848, d 0.003, lr: 0.0001961, consume 354.03s
step 249000, loss 0.751, rec 0.063, kl 0.023, pl 0.018, g 0.647, w 0.651, d 0.004, lr: 0.0001951, consume 354.07s
step 249500, loss 0.740, rec 0.063, kl 0.023, pl 0.018, g 0.635, w 0.639, d 0.004, lr: 0.0001940, consume 353.91s
step 250000, loss 0.472, rec 0.063, kl 0.023, pl 0.018, g 0.369, w 0.371, d 0.003, lr: 0.0001929, consume 353.84s
step 250500, loss 0.420, rec 0.063, kl 0.023, pl 0.018, g 0.316, w 0.318, d 0.002, lr: 0.0001918, consume 354.45s
step 251000, loss 0.314, rec 0.062, kl 0.023, pl 0.018, g 0.211, w 0.212, d 0.002, lr: 0.0001908, consume 354.16s
step 251500, loss 0.327, rec 0.063, kl 0.023, pl 0.018, g 0.224, w 0.225, d 0.002, lr: 0.0001897, consume 353.78s
step 252000, loss 0.281, rec 0.063, kl 0.023, pl 0.018, g 0.178, w 0.178, d 0.002, lr: 0.0001886, consume 353.76s
step 252500, loss 0.332, rec 0.063, kl 0.023, pl 0.018, g 0.228, w 0.229, d 0.004, lr: 0.0001876, consume 354.63s
step 253000, loss 0.743, rec 0.063, kl 0.023, pl 0.018, g 0.639, w 0.643, d 0.003, lr: 0.0001865, consume 353.77s
step 253500, loss 0.866, rec 0.064, kl 0.023, pl 0.018, g 0.762, w 0.767, d 0.003, lr: 0.0001854, consume 353.73s
    valid loss: 100.031, rec 0.100, kl 98.891, pl 0.025, g 1.015, w 1.000, d 1.002, consume: 147.806s
epoch: 37, consume: 4882.452s
step 254000, loss 0.787, rec 0.063, kl 0.023, pl 0.018, g 0.684, w 0.688, d 0.003, lr: 0.0001844, consume 324.99s
step 254500, loss 0.755, rec 0.063, kl 0.023, pl 0.018, g 0.651, w 0.655, d 0.003, lr: 0.0001833, consume 354.39s
step 255000, loss 1.055, rec 0.063, kl 0.023, pl 0.018, g 0.951, w 0.956, d 0.003, lr: 0.0001823, consume 354.31s
step 255500, loss 1.005, rec 0.064, kl 0.023, pl 0.018, g 0.901, w 0.906, d 0.003, lr: 0.0001812, consume 353.91s
step 256000, loss 1.130, rec 0.064, kl 0.023, pl 0.018, g 1.026, w 1.032, d 0.003, lr: 0.0001802, consume 354.21s
step 256500, loss 1.095, rec 0.064, kl 0.023, pl 0.018, g 0.990, w 0.996, d 0.003, lr: 0.0001791, consume 354.26s
step 257000, loss 0.697, rec 0.064, kl 0.023, pl 0.018, g 0.593, w 0.596, d 0.003, lr: 0.0001781, consume 353.98s
step 257500, loss 0.685, rec 0.063, kl 0.023, pl 0.018, g 0.581, w 0.585, d 0.003, lr: 0.0001770, consume 354.48s
step 258000, loss 0.976, rec 0.064, kl 0.023, pl 0.018, g 0.871, w 0.877, d 0.003, lr: 0.0001760, consume 354.08s
step 258500, loss 0.847, rec 0.063, kl 0.023, pl 0.018, g 0.743, w 0.747, d 0.003, lr: 0.0001749, consume 354.15s
step 259000, loss 0.553, rec 0.063, kl 0.023, pl 0.018, g 0.449, w 0.452, d 0.003, lr: 0.0001739, consume 353.84s
step 259500, loss 0.478, rec 0.064, kl 0.023, pl 0.018, g 0.374, w 0.376, d 0.003, lr: 0.0001728, consume 354.21s
step 260000, loss 0.337, rec 0.063, kl 0.023, pl 0.018, g 0.234, w 0.235, d 0.002, lr: 0.0001718, consume 354.45s
    valid loss: 4.889, rec 0.084, kl 3.896, pl 0.023, g 0.885, w 1.000, d 1.087, consume: 147.960s
epoch: 38, consume: 4884.638s
step 260500, loss 0.309, rec 0.062, kl 0.023, pl 0.018, g 0.206, w 0.207, d 0.013, lr: 0.0001708, consume 203.57s
step 261000, loss 1.346, rec 0.064, kl 0.023, pl 0.018, g 1.240, w 1.248, d 0.003, lr: 0.0001697, consume 353.96s
step 261500, loss 1.053, rec 0.064, kl 0.023, pl 0.018, g 0.948, w 0.953, d 0.003, lr: 0.0001687, consume 353.85s
step 262000, loss 0.770, rec 0.063, kl 0.023, pl 0.018, g 0.666, w 0.670, d 0.003, lr: 0.0001677, consume 354.94s
step 262500, loss 0.993, rec 0.064, kl 0.023, pl 0.018, g 0.888, w 0.894, d 0.003, lr: 0.0001666, consume 353.98s
step 263000, loss 0.995, rec 0.064, kl 0.023, pl 0.018, g 0.890, w 0.895, d 0.003, lr: 0.0001656, consume 354.00s
step 263500, loss 0.937, rec 0.064, kl 0.023, pl 0.018, g 0.833, w 0.838, d 0.003, lr: 0.0001646, consume 354.54s
step 264000, loss 0.838, rec 0.063, kl 0.023, pl 0.018, g 0.734, w 0.739, d 0.003, lr: 0.0001636, consume 354.67s
step 264500, loss 0.998, rec 0.063, kl 0.023, pl 0.018, g 0.894, w 0.899, d 0.003, lr: 0.0001626, consume 354.09s
step 265000, loss 0.956, rec 0.063, kl 0.023, pl 0.018, g 0.852, w 0.857, d 0.004, lr: 0.0001615, consume 353.94s
step 265500, loss 0.913, rec 0.063, kl 0.023, pl 0.018, g 0.809, w 0.814, d 0.003, lr: 0.0001605, consume 354.13s
step 266000, loss 0.772, rec 0.064, kl 0.023, pl 0.018, g 0.668, w 0.672, d 0.003, lr: 0.0001595, consume 354.26s
step 266500, loss 0.568, rec 0.063, kl 0.023, pl 0.018, g 0.464, w 0.467, d 0.003, lr: 0.0001585, consume 354.37s
    valid loss: 205.710, rec 0.088, kl 204.621, pl 0.023, g 0.978, w 1.000, d 1.030, consume: 148.158s
epoch: 39, consume: 4885.603s
step 267000, loss 0.157, rec 0.062, kl 0.023, pl 0.018, g 0.054, w 0.048, d 0.015, lr: 0.0001575, consume 81.80s
step 267500, loss 0.825, rec 0.062, kl 0.023, pl 0.018, g 0.722, w 0.725, d 0.005, lr: 0.0001565, consume 354.37s
step 268000, loss 1.154, rec 0.064, kl 0.023, pl 0.018, g 1.050, w 1.057, d 0.003, lr: 0.0001555, consume 354.12s
step 268500, loss 1.123, rec 0.064, kl 0.023, pl 0.018, g 1.019, w 1.025, d 0.003, lr: 0.0001545, consume 354.42s
step 269000, loss 1.234, rec 0.064, kl 0.023, pl 0.018, g 1.130, w 1.137, d 0.003, lr: 0.0001535, consume 354.38s
step 269500, loss 1.031, rec 0.063, kl 0.023, pl 0.018, g 0.927, w 0.933, d 0.003, lr: 0.0001525, consume 354.26s
step 270000, loss 1.150, rec 0.064, kl 0.023, pl 0.018, g 1.046, w 1.053, d 0.003, lr: 0.0001515, consume 354.15s
step 270500, loss 1.035, rec 0.064, kl 0.023, pl 0.018, g 0.931, w 0.936, d 0.003, lr: 0.0001505, consume 354.00s
step 271000, loss 1.063, rec 0.064, kl 0.023, pl 0.018, g 0.959, w 0.964, d 0.003, lr: 0.0001495, consume 354.72s
step 271500, loss 1.096, rec 0.064, kl 0.023, pl 0.018, g 0.992, w 0.998, d 0.003, lr: 0.0001485, consume 354.23s
step 272000, loss 1.045, rec 0.064, kl 0.023, pl 0.018, g 0.941, w 0.947, d 0.003, lr: 0.0001476, consume 353.80s
step 272500, loss 0.960, rec 0.064, kl 0.023, pl 0.018, g 0.856, w 0.861, d 0.003, lr: 0.0001466, consume 353.96s
step 273000, loss 0.963, rec 0.063, kl 0.023, pl 0.018, g 0.860, w 0.865, d 0.003, lr: 0.0001456, consume 354.43s
step 273500, loss 0.991, rec 0.064, kl 0.023, pl 0.018, g 0.887, w 0.892, d 0.003, lr: 0.0001446, consume 354.80s
    valid loss: 361.174, rec 0.091, kl 360.071, pl 0.024, g 0.990, w 1.000, d 1.000, consume: 148.103s
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.95it/s]
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.46it/s]
FID:  300.62553580764137
epoch: 40, consume: 4939.702s
step 274000, loss 0.976, rec 0.063, kl 0.023, pl 0.018, g 0.873, w 0.878, d 0.003, lr: 0.0001437, consume 314.21s
step 274500, loss 1.139, rec 0.063, kl 0.023, pl 0.018, g 1.035, w 1.041, d 0.003, lr: 0.0001427, consume 356.92s
step 275000, loss 1.289, rec 0.064, kl 0.023, pl 0.018, g 1.185, w 1.192, d 0.003, lr: 0.0001417, consume 354.69s
step 275500, loss 1.272, rec 0.064, kl 0.022, pl 0.018, g 1.168, w 1.175, d 0.003, lr: 0.0001407, consume 354.45s
step 276000, loss 1.155, rec 0.064, kl 0.023, pl 0.018, g 1.051, w 1.057, d 0.003, lr: 0.0001398, consume 353.96s
step 276500, loss 0.985, rec 0.064, kl 0.023, pl 0.018, g 0.881, w 0.886, d 0.003, lr: 0.0001388, consume 354.17s
step 277000, loss 1.093, rec 0.064, kl 0.023, pl 0.018, g 0.989, w 0.995, d 0.003, lr: 0.0001379, consume 354.06s
step 277500, loss 1.144, rec 0.064, kl 0.023, pl 0.018, g 1.040, w 1.046, d 0.003, lr: 0.0001369, consume 353.86s
step 278000, loss 1.218, rec 0.063, kl 0.023, pl 0.018, g 1.114, w 1.120, d 0.003, lr: 0.0001360, consume 354.28s
step 278500, loss 1.159, rec 0.063, kl 0.023, pl 0.018, g 1.055, w 1.061, d 0.003, lr: 0.0001350, consume 354.25s
step 279000, loss 1.404, rec 0.064, kl 0.023, pl 0.018, g 1.300, w 1.308, d 0.003, lr: 0.0001341, consume 354.27s
step 279500, loss 1.287, rec 0.063, kl 0.023, pl 0.018, g 1.183, w 1.190, d 0.003, lr: 0.0001331, consume 353.91s
step 280000, loss 1.467, rec 0.064, kl 0.023, pl 0.018, g 1.362, w 1.370, d 0.003, lr: 0.0001322, consume 353.67s
    valid loss: 774.373, rec 0.105, kl 773.245, pl 0.024, g 0.999, w 1.000, d 1.000, consume: 147.838s
epoch: 41, consume: 4887.957s
step 280500, loss 1.302, rec 0.063, kl 0.023, pl 0.018, g 1.198, w 1.205, d 0.003, lr: 0.0001312, consume 192.49s
step 281000, loss 1.204, rec 0.064, kl 0.023, pl 0.018, g 1.100, w 1.106, d 0.003, lr: 0.0001303, consume 355.15s
step 281500, loss 1.215, rec 0.063, kl 0.023, pl 0.018, g 1.111, w 1.117, d 0.003, lr: 0.0001294, consume 355.06s
step 282000, loss 1.099, rec 0.064, kl 0.023, pl 0.018, g 0.995, w 1.001, d 0.003, lr: 0.0001284, consume 354.41s
step 282500, loss 1.058, rec 0.064, kl 0.023, pl 0.018, g 0.954, w 0.959, d 0.003, lr: 0.0001275, consume 354.55s
step 283000, loss 1.073, rec 0.063, kl 0.023, pl 0.018, g 0.969, w 0.975, d 0.003, lr: 0.0001266, consume 353.79s
step 283500, loss 0.907, rec 0.063, kl 0.023, pl 0.018, g 0.804, w 0.809, d 0.003, lr: 0.0001256, consume 353.84s
step 284000, loss 0.595, rec 0.063, kl 0.023, pl 0.018, g 0.492, w 0.495, d 0.003, lr: 0.0001247, consume 354.19s
step 284500, loss 0.135, rec 0.063, kl 0.023, pl 0.018, g 0.031, w 0.034, d 0.267, lr: 0.0001238, consume 354.74s
step 285000, loss 0.129, rec 0.064, kl 0.023, pl 0.018, g 0.025, w 0.722, d 0.323, lr: 0.0001229, consume 353.89s
step 285500, loss 0.794, rec 0.063, kl 0.023, pl 0.018, g 0.690, w 0.694, d 0.003, lr: 0.0001220, consume 354.16s
step 286000, loss 0.918, rec 0.063, kl 0.023, pl 0.018, g 0.814, w 0.819, d 0.003, lr: 0.0001211, consume 354.74s
step 286500, loss 0.989, rec 0.063, kl 0.023, pl 0.018, g 0.886, w 0.891, d 0.003, lr: 0.0001202, consume 354.28s
    valid loss: 221.004, rec 0.087, kl 219.905, pl 0.023, g 0.989, w 1.000, d 1.003, consume: 148.088s
epoch: 42, consume: 4888.325s
step 287000, loss 1.166, rec 0.064, kl 0.023, pl 0.018, g 1.062, w 1.068, d 0.006, lr: 0.0001193, consume 70.64s
step 287500, loss 0.956, rec 0.063, kl 0.023, pl 0.018, g 0.853, w 0.858, d 0.003, lr: 0.0001184, consume 353.80s
step 288000, loss 1.001, rec 0.063, kl 0.023, pl 0.018, g 0.897, w 0.903, d 0.003, lr: 0.0001175, consume 354.17s
step 288500, loss 0.913, rec 0.064, kl 0.023, pl 0.018, g 0.809, w 0.814, d 0.003, lr: 0.0001166, consume 354.14s
step 289000, loss 0.872, rec 0.063, kl 0.023, pl 0.018, g 0.768, w 0.773, d 0.003, lr: 0.0001157, consume 354.35s
step 289500, loss 0.778, rec 0.063, kl 0.023, pl 0.018, g 0.674, w 0.678, d 0.003, lr: 0.0001148, consume 354.28s
step 290000, loss 0.812, rec 0.063, kl 0.023, pl 0.018, g 0.708, w 0.713, d 0.003, lr: 0.0001139, consume 354.15s
step 290500, loss 0.864, rec 0.063, kl 0.023, pl 0.018, g 0.761, w 0.765, d 0.003, lr: 0.0001130, consume 353.91s
step 291000, loss 0.751, rec 0.063, kl 0.023, pl 0.018, g 0.648, w 0.651, d 0.003, lr: 0.0001121, consume 353.58s
step 291500, loss 0.881, rec 0.064, kl 0.023, pl 0.018, g 0.777, w 0.782, d 0.003, lr: 0.0001113, consume 354.30s
step 292000, loss 0.407, rec 0.062, kl 0.023, pl 0.018, g 0.305, w 0.306, d 0.003, lr: 0.0001104, consume 354.04s
step 292500, loss 0.300, rec 0.062, kl 0.023, pl 0.018, g 0.198, w 0.199, d 0.002, lr: 0.0001095, consume 353.61s
step 293000, loss 0.412, rec 0.062, kl 0.023, pl 0.018, g 0.310, w 0.311, d 0.002, lr: 0.0001086, consume 353.70s
step 293500, loss 0.774, rec 0.063, kl 0.023, pl 0.018, g 0.671, w 0.676, d 0.004, lr: 0.0001078, consume 354.07s
    valid loss: 221.696, rec 0.084, kl 220.601, pl 0.023, g 0.989, w 1.000, d 1.010, consume: 147.886s
epoch: 43, consume: 4883.186s
step 294000, loss 0.604, rec 0.063, kl 0.023, pl 0.018, g 0.501, w 0.504, d 0.003, lr: 0.0001069, consume 302.43s
step 294500, loss 0.436, rec 0.063, kl 0.023, pl 0.018, g 0.333, w 0.335, d 0.002, lr: 0.0001061, consume 353.93s
step 295000, loss 0.353, rec 0.062, kl 0.023, pl 0.018, g 0.250, w 0.251, d 0.002, lr: 0.0001052, consume 354.12s
step 295500, loss 0.281, rec 0.062, kl 0.023, pl 0.018, g 0.179, w 0.179, d 0.032, lr: 0.0001044, consume 354.25s
step 296000, loss 0.377, rec 0.062, kl 0.023, pl 0.018, g 0.274, w 0.276, d 0.002, lr: 0.0001035, consume 354.30s
step 296500, loss 0.389, rec 0.062, kl 0.023, pl 0.018, g 0.287, w 0.288, d 0.002, lr: 0.0001027, consume 353.89s
step 297000, loss 0.400, rec 0.062, kl 0.023, pl 0.018, g 0.298, w 0.299, d 0.003, lr: 0.0001018, consume 355.41s
step 297500, loss 0.423, rec 0.062, kl 0.023, pl 0.018, g 0.321, w 0.323, d 0.002, lr: 0.0001010, consume 355.00s
step 298000, loss 0.649, rec 0.062, kl 0.023, pl 0.018, g 0.546, w 0.549, d 0.003, lr: 0.0001001, consume 354.60s
step 298500, loss 0.634, rec 0.062, kl 0.023, pl 0.018, g 0.531, w 0.534, d 0.003, lr: 0.0000993, consume 355.19s
step 299000, loss 0.762, rec 0.063, kl 0.023, pl 0.018, g 0.659, w 0.663, d 0.003, lr: 0.0000985, consume 355.50s
step 299500, loss 0.784, rec 0.063, kl 0.023, pl 0.018, g 0.681, w 0.685, d 0.003, lr: 0.0000976, consume 355.34s
step 300000, loss 1.081, rec 0.064, kl 0.023, pl 0.018, g 0.977, w 0.982, d 0.003, lr: 0.0000968, consume 353.79s
    valid loss: 148.874, rec 0.086, kl 147.794, pl 0.023, g 0.971, w 1.000, d 1.003, consume: 147.726s
epoch: 44, consume: 4889.446s
step 300500, loss 1.023, rec 0.063, kl 0.023, pl 0.018, g 0.920, w 0.926, d 0.003, lr: 0.0000960, consume 181.26s
step 301000, loss 1.078, rec 0.063, kl 0.023, pl 0.018, g 0.975, w 0.981, d 0.003, lr: 0.0000952, consume 354.55s
step 301500, loss 1.371, rec 0.063, kl 0.023, pl 0.018, g 1.268, w 1.275, d 0.003, lr: 0.0000944, consume 354.08s
step 302000, loss 1.285, rec 0.063, kl 0.023, pl 0.018, g 1.181, w 1.188, d 0.003, lr: 0.0000936, consume 353.99s
step 302500, loss 1.226, rec 0.064, kl 0.023, pl 0.018, g 1.122, w 1.129, d 0.003, lr: 0.0000927, consume 354.23s
step 303000, loss 1.363, rec 0.063, kl 0.023, pl 0.018, g 1.260, w 1.267, d 0.003, lr: 0.0000919, consume 354.72s
step 303500, loss 1.290, rec 0.064, kl 0.023, pl 0.018, g 1.186, w 1.193, d 0.003, lr: 0.0000911, consume 353.90s
step 304000, loss 1.451, rec 0.064, kl 0.023, pl 0.018, g 1.347, w 1.355, d 0.003, lr: 0.0000903, consume 353.84s
step 304500, loss 1.333, rec 0.063, kl 0.023, pl 0.018, g 1.230, w 1.237, d 0.003, lr: 0.0000895, consume 354.19s
step 305000, loss 1.430, rec 0.063, kl 0.023, pl 0.018, g 1.327, w 1.335, d 0.003, lr: 0.0000888, consume 354.19s
step 305500, loss 1.324, rec 0.063, kl 0.023, pl 0.018, g 1.220, w 1.228, d 0.003, lr: 0.0000880, consume 354.58s
step 306000, loss 1.259, rec 0.063, kl 0.023, pl 0.018, g 1.156, w 1.162, d 0.003, lr: 0.0000872, consume 353.85s
step 306500, loss 1.376, rec 0.064, kl 0.023, pl 0.018, g 1.272, w 1.280, d 0.003, lr: 0.0000864, consume 354.37s
    valid loss: 1.101, rec 0.089, kl 0.023, pl 0.023, g 0.966, w 1.000, d 1.007, consume: 147.915s
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.47it/s]
100%|███████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.97it/s]
FID:  305.00498600218594
epoch: 45, consume: 4936.733s
step 307000, loss 1.509, rec 0.064, kl 0.023, pl 0.018, g 1.405, w 1.413, d 0.003, lr: 0.0000856, consume 59.41s
step 307500, loss 1.570, rec 0.063, kl 0.023, pl 0.018, g 1.466, w 1.474, d 0.003, lr: 0.0000848, consume 354.57s
step 308000, loss 1.482, rec 0.064, kl 0.023, pl 0.018, g 1.379, w 1.386, d 0.003, lr: 0.0000841, consume 354.47s
step 308500, loss 1.548, rec 0.063, kl 0.023, pl 0.018, g 1.444, w 1.453, d 0.003, lr: 0.0000833, consume 354.31s
step 309000, loss 1.372, rec 0.064, kl 0.023, pl 0.018, g 1.267, w 1.275, d 0.003, lr: 0.0000825, consume 353.96s
step 309500, loss 1.278, rec 0.063, kl 0.023, pl 0.018, g 1.174, w 1.181, d 0.003, lr: 0.0000818, consume 353.93s
step 310000, loss 1.077, rec 0.063, kl 0.023, pl 0.018, g 0.973, w 0.979, d 0.003, lr: 0.0000810, consume 354.83s
step 310500, loss 1.176, rec 0.063, kl 0.023, pl 0.018, g 1.073, w 1.079, d 0.003, lr: 0.0000803, consume 354.38s
step 311000, loss 1.230, rec 0.063, kl 0.023, pl 0.018, g 1.126, w 1.133, d 0.003, lr: 0.0000795, consume 353.99s
step 311500, loss 1.232, rec 0.063, kl 0.023, pl 0.018, g 1.128, w 1.136, d 0.003, lr: 0.0000788, consume 353.87s
step 312000, loss 1.009, rec 0.063, kl 0.023, pl 0.018, g 0.905, w 0.912, d 0.003, lr: 0.0000780, consume 354.59s
step 312500, loss 0.845, rec 0.063, kl 0.023, pl 0.018, g 0.741, w 0.746, d 0.003, lr: 0.0000773, consume 354.33s
step 313000, loss 0.265, rec 0.062, kl 0.023, pl 0.018, g 0.162, w 0.162, d 0.008, lr: 0.0000765, consume 353.92s
step 313500, loss 0.206, rec 0.061, kl 0.023, pl 0.018, g 0.104, w 0.104, d 0.001, lr: 0.0000758, consume 354.31s
    valid loss: 1.114, rec 0.082, kl 0.023, pl 0.023, g 0.986, w 1.000, d 1.005, consume: 148.068s
epoch: 46, consume: 4886.872s
step 314000, loss 0.847, rec 0.063, kl 0.023, pl 0.018, g 0.744, w 0.749, d 0.003, lr: 0.0000751, consume 291.59s
step 314500, loss 1.361, rec 0.063, kl 0.023, pl 0.018, g 1.257, w 1.264, d 0.003, lr: 0.0000744, consume 354.57s
step 315000, loss 1.052, rec 0.063, kl 0.023, pl 0.018, g 0.948, w 0.954, d 0.003, lr: 0.0000736, consume 354.11s
step 315500, loss 0.906, rec 0.063, kl 0.023, pl 0.018, g 0.803, w 0.808, d 0.003, lr: 0.0000729, consume 354.50s
step 316000, loss 0.739, rec 0.062, kl 0.023, pl 0.018, g 0.636, w 0.640, d 0.003, lr: 0.0000722, consume 356.11s
step 316500, loss 0.672, rec 0.062, kl 0.023, pl 0.018, g 0.570, w 0.573, d 0.003, lr: 0.0000715, consume 354.75s
step 317000, loss 0.816, rec 0.062, kl 0.023, pl 0.018, g 0.714, w 0.718, d 0.003, lr: 0.0000708, consume 354.31s
step 317500, loss 1.187, rec 0.062, kl 0.023, pl 0.018, g 1.084, w 1.090, d 0.003, lr: 0.0000701, consume 354.69s
step 318000, loss 1.528, rec 0.063, kl 0.023, pl 0.018, g 1.424, w 1.432, d 0.003, lr: 0.0000694, consume 354.80s
step 318500, loss 1.592, rec 0.063, kl 0.023, pl 0.018, g 1.489, w 1.499, d 0.003, lr: 0.0000687, consume 354.30s
step 319000, loss 1.738, rec 0.063, kl 0.023, pl 0.018, g 1.634, w 1.646, d 0.003, lr: 0.0000680, consume 354.68s
step 319500, loss 1.431, rec 0.063, kl 0.023, pl 0.018, g 1.327, w 1.337, d 0.003, lr: 0.0000673, consume 354.66s
step 320000, loss 1.353, rec 0.063, kl 0.023, pl 0.018, g 1.250, w 1.259, d 0.003, lr: 0.0000666, consume 354.91s
    valid loss: 1.147, rec 0.093, kl 0.030, pl 0.023, g 1.001, w 1.000, d 1.000, consume: 147.985s
epoch: 47, consume: 4891.659s
step 320500, loss 0.997, rec 0.063, kl 0.023, pl 0.018, g 0.893, w 0.900, d 0.003, lr: 0.0000659, consume 169.57s
step 321000, loss 1.091, rec 0.063, kl 0.023, pl 0.018, g 0.988, w 0.995, d 0.003, lr: 0.0000653, consume 354.89s
step 321500, loss 1.309, rec 0.063, kl 0.023, pl 0.018, g 1.206, w 1.214, d 0.003, lr: 0.0000646, consume 355.33s
step 322000, loss 1.396, rec 0.063, kl 0.023, pl 0.018, g 1.292, w 1.300, d 0.003, lr: 0.0000639, consume 354.66s
step 322500, loss 1.289, rec 0.063, kl 0.023, pl 0.018, g 1.186, w 1.194, d 0.003, lr: 0.0000632, consume 354.71s
step 323000, loss 1.419, rec 0.063, kl 0.023, pl 0.018, g 1.315, w 1.325, d 0.003, lr: 0.0000626, consume 355.04s
step 323500, loss 1.092, rec 0.063, kl 0.023, pl 0.018, g 0.989, w 0.996, d 0.003, lr: 0.0000619, consume 355.48s
step 324000, loss 1.160, rec 0.063, kl 0.023, pl 0.018, g 1.056, w 1.064, d 0.003, lr: 0.0000613, consume 355.49s
step 324500, loss 1.287, rec 0.063, kl 0.023, pl 0.018, g 1.184, w 1.192, d 0.003, lr: 0.0000606, consume 356.14s
step 325000, loss 1.339, rec 0.063, kl 0.023, pl 0.018, g 1.236, w 1.244, d 0.003, lr: 0.0000600, consume 355.05s
step 325500, loss 1.243, rec 0.063, kl 0.023, pl 0.018, g 1.139, w 1.147, d 0.003, lr: 0.0000593, consume 354.82s
step 326000, loss 1.093, rec 0.063, kl 0.023, pl 0.018, g 0.989, w 0.996, d 0.003, lr: 0.0000587, consume 355.01s
step 326500, loss 1.195, rec 0.063, kl 0.023, pl 0.018, g 1.091, w 1.099, d 0.003, lr: 0.0000580, consume 355.17s
    valid loss: 368.386, rec 0.102, kl 367.265, pl 0.025, g 0.995, w 1.000, d 1.003, consume: 147.534s
epoch: 48, consume: 4896.861s
